# Natural_Language_Processing_Course
This repository contains the code and resources for the Natural Language Processing (NLP) course assignments at the  University of Tehran,Spring 2023. 

The assignments focuses on implementing various NLP techniques and algorithms to solve a range of language processing tasks.

# CA3 - Sentiment Analysis using Recurrent Neural Networks
  * Q1: RNN
    
     This project focuses on training a simple recurrent neural network (RNN) using PyTorch to predict sentiment on the Sentiment140 dataset. Prior to training the RNN, the dataset is preprocessed. Different embedding techniques, such as one-hot encoding, Word2Vec, and GloVe, are explored to enhance the RNN model's performance, and their effectiveness is evaluated. The trained RNN model is then assessed using standard evaluation metrics to determine its accuracy in sentiment prediction.
    
  * Q2: LSTM vs GRU

     This assignment focuses on training LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) models on the Sentiment140 dataset for sentiment analysis. The objective is to compare the performance of these models and evaluate their effectiveness in sentiment prediction. Two different embedding techniques, GloVe and one-hot encoding, are used to represent the text.

# CA4 - Transformers
  * Q1: ParsBERT 
  
     The assignment involves analyzing the performance of ParsBERT, a state-of-the-art pre-trained language model specifically designed for Persian text, on the NLI task. We will explore the effects of modifying the architecture and adjusting various parameters of ParsBERT on its accuracy and overall performance.
  * Q2: Zero-Shot Learning
 
     In this question, we aim to design a model that can measure the level of user satisfaction with the food ordered through Snapp Food using zero-shot learning.
  
